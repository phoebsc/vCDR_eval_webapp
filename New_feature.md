fixing old features
1. in the database, when i click the run id for full details, the prompts are not loading. could you check that the dynamic prompt selection is actually being saved and retrieved properly in the database?

new feature:
1. I want to add quality metrics for the benchmark runs. These quality metrics are generated with code in a different repo (the file in that repo that i'm calling is extract_responses.py, but i'm only pasting it here as an example). please help me think of a way to integrate scripts from another repo without keeping several versions of the same scripts in different repos or directories.  